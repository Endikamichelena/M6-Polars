# -*- coding: utf-8 -*-
"""Polars - Group assignment 2b.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VsEvjgviWhLaqhfBTYsJ0QdD5g5sHqJS

# Prepare the data and basic EDA

## Data loading

**Remember to load the kaggle.json file before running the code, this is to create the API.**
"""

# install
!pip install kaggle
!pip install polars

# import
import os 

# environment
os.environ['KAGGLE_CONFIG_DIR'] = '/content'

# download the data
! kaggle datasets download -d davidgauthier/glassdoor-job-reviews

# unzip it
! unzip \*.zip

"""## Understanding the data"""

# import
import polars as pl

# load the data
df = pl.read_csv("/content/glassdoor_reviews.csv")
# check the data
df

# check columns
df.columns

# check data type
df.dtypes

# count the rows
rowCount = df.shape[0]
print("Total number of rows in the dataset:", rowCount)

# display the number of unique values in the 'firm' column
uniqueSeasons = df['firm'].n_unique()
print("Number of unique values in the 'firm' column:", uniqueSeasons)

# find the null data
null_count_df = df.null_count()
# check null data count
null_count_df

"""## Data cleaning

Before cleaning the data, we first select the interesting columns in our dataset
"""

# select interesting columns in order to work on a new df
df = df.select(
    ['firm', 'date_review', 'job_title', 'location', 'work_life_balance', 'diversity_inclusion']
)
# check the data
df

# find the null data in our new df
null_count_df = df.null_count()
# check null data count
null_count_df

"""As there are many null values in the 'diversity_inclusion' column, we will just drop it"""

# drop the column
df = df.drop('diversity_inclusion')
#check the data
df.head()

# drop now the missing values
df = df.drop_nulls()
# check the data
df

"""## Data visualization

Perform a basic count on which companies have the most job offers
"""

# create a group by to see how many job offers are posted by each firm, order it
job_offers_companies_df = df.groupby('firm').count()
# check the data
job_offers_companies_df

# sort the df
job_offers_companies_df = job_offers_companies_df.sort('count').reverse()
# check the data
job_offers_companies_df

"""We are gonna filter the 'job_offers_companies_df' for those companies that have more than 9000 job offers, in order to get meaningful insights on companies that used the platform to hire employees:"""

# filter
job_offers_companies_df = job_offers_companies_df.filter(pl.col("count") > 9000)
# check the data
job_offers_companies_df

"""Now, get a df which includes these companies and all the features selected at the beginning of this chapter:"""

# create a list
list = job_offers_companies_df['firm'].to_list()

# filter the df using the list extracted before
popular_companies_df = df.filter((pl.col("firm").is_in(list)))
# rename the data
df = popular_companies_df
# check the data
df

"""Visualize the **work life balance** feature using both histogram and pie chart"""

# group by the df by the interesting feature and count the number of firms offering job positions
df_work_life_balance = df.groupby('work_life_balance').agg(pl.col('firm').count().alias('number of companies'))
# check the data 
df_work_life_balance

# import
import matplotlib.pyplot as plt
# visualize a histogram
plt.bar(df_work_life_balance['work_life_balance'], df_work_life_balance['number of companies'])

# import
import plotly.express as px
# visualize pie chart with plotly
px.pie(df_work_life_balance,                              
    names = df_work_life_balance['work_life_balance'],
    values = df_work_life_balance['number of companies'],
    color_discrete_sequence= px.colors.sequential.Plasma_r)

"""Visualize data based on the **job title** feature in order to see which kind of jobs are popular"""

# create the df using groupby
df_job_title = df.groupby('job_title').count().sort(by='count')
# get the top 20 job positions
df_job_title = df_job_title.tail(25)
# check the data
df_job_title

# drop the "" row
df_job_title = df_job_title.filter(pl.col('count') != 6812)
# check the data
df_job_title

# convert the Polars DataFrame to a pandas DataFrame
df_pd = df_job_title.to_pandas()

# set the width and height of the figure
plt.figure(figsize=(10,6))

# add title
plt.title("Popular job positions")

# create a bar chart
sns.barplot(x=df_pd['count'], y=df_pd['job_title'])

# add label for vertical axis
plt.ylabel("Job Titles")

"""Visualize the **average work life balance** per each company"""

# create the df using groupby to see the avg work life balance per company
average_work_life_balance = df.groupby('firm').agg(pl.col('work_life_balance').mean())
# chech the data
average_work_life_balance

# convert the Polars DataFrame to a pandas DataFrame
df_pd = average_work_life_balance.to_pandas()

# set the width and height of the figure
plt.figure(figsize=(10,6))

# add title
plt.title("Average work life balance per company")

# create a bar chart
sns.barplot(x=df_pd['work_life_balance'], y=df_pd['firm'])

# add label for vertical axis
plt.ylabel("Copmanies")

"""Visualize **each firms work life balance** according to it's job offers"""

# set the width and height of the figure
plt.figure(figsize=(8,12))

# add title
plt.title("Work life balance & companies")

# histograms for each firm & work life balances
sns.histplot(data=df, x='work_life_balance', hue='firm', bins=20, palette='Dark2')

# add label for vertical axis
plt.ylabel("Count of job offers within life balance rate")